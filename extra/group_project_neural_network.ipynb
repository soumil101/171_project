{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV, RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset :\n",
      "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
      "0   40   M           ATA        140          289          0     Normal    172   \n",
      "1   49   F           NAP        160          180          0     Normal    156   \n",
      "2   37   M           ATA        130          283          0         ST     98   \n",
      "3   48   F           ASY        138          214          0     Normal    108   \n",
      "4   54   M           NAP        150          195          0     Normal    122   \n",
      "\n",
      "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
      "0              N      0.0       Up             0  \n",
      "1              N      1.0     Flat             1  \n",
      "2              N      0.0       Up             0  \n",
      "3              Y      1.5     Flat             1  \n",
      "4              N      0.0       Up             0  \n",
      "Dimensions of the dataset :  (918, 12)\n",
      "Features of the dataset :\n",
      "               Age  Sex ChestPainType   RestingBP  Cholesterol   FastingBS  \\\n",
      "count   918.000000  918           918  918.000000   918.000000  918.000000   \n",
      "unique         NaN    2             4         NaN          NaN         NaN   \n",
      "top            NaN    M           ASY         NaN          NaN         NaN   \n",
      "freq           NaN  725           496         NaN          NaN         NaN   \n",
      "mean     53.510893  NaN           NaN  132.396514   198.799564    0.233115   \n",
      "std       9.432617  NaN           NaN   18.514154   109.384145    0.423046   \n",
      "min      28.000000  NaN           NaN    0.000000     0.000000    0.000000   \n",
      "25%      47.000000  NaN           NaN  120.000000   173.250000    0.000000   \n",
      "50%      54.000000  NaN           NaN  130.000000   223.000000    0.000000   \n",
      "75%      60.000000  NaN           NaN  140.000000   267.000000    0.000000   \n",
      "max      77.000000  NaN           NaN  200.000000   603.000000    1.000000   \n",
      "\n",
      "       RestingECG       MaxHR ExerciseAngina     Oldpeak ST_Slope  \\\n",
      "count         918  918.000000            918  918.000000      918   \n",
      "unique          3         NaN              2         NaN        3   \n",
      "top        Normal         NaN              N         NaN     Flat   \n",
      "freq          552         NaN            547         NaN      460   \n",
      "mean          NaN  136.809368            NaN    0.887364      NaN   \n",
      "std           NaN   25.460334            NaN    1.066570      NaN   \n",
      "min           NaN   60.000000            NaN   -2.600000      NaN   \n",
      "25%           NaN  120.000000            NaN    0.000000      NaN   \n",
      "50%           NaN  138.000000            NaN    0.600000      NaN   \n",
      "75%           NaN  156.000000            NaN    1.500000      NaN   \n",
      "max           NaN  202.000000            NaN    6.200000      NaN   \n",
      "\n",
      "        HeartDisease  \n",
      "count     918.000000  \n",
      "unique           NaN  \n",
      "top              NaN  \n",
      "freq             NaN  \n",
      "mean        0.553377  \n",
      "std         0.497414  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         1.000000  \n",
      "75%         1.000000  \n",
      "max         1.000000  \n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"heart.csv\")\n",
    "print(\"Dataset :\")\n",
    "print(dataset.head())\n",
    "\n",
    "print(\"Dimensions of the dataset : \", dataset.shape)\n",
    "print(\"Features of the dataset :\")\n",
    "print(dataset.describe(include = 'all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processed data :\n",
      "          Age  RestingBP  Cholesterol  FastingBS     MaxHR   Oldpeak\n",
      "0    0.244898       0.70     0.479270        0.0  0.788732  0.295455\n",
      "1    0.428571       0.80     0.298507        0.0  0.676056  0.409091\n",
      "2    0.183673       0.65     0.469320        0.0  0.267606  0.295455\n",
      "3    0.408163       0.69     0.354892        0.0  0.338028  0.465909\n",
      "4    0.530612       0.75     0.323383        0.0  0.436620  0.295455\n",
      "..        ...        ...          ...        ...       ...       ...\n",
      "913  0.346939       0.55     0.437811        0.0  0.507042  0.431818\n",
      "914  0.816327       0.72     0.320066        1.0  0.570423  0.681818\n",
      "915  0.591837       0.65     0.217247        0.0  0.387324  0.431818\n",
      "916  0.591837       0.65     0.391376        0.0  0.802817  0.295455\n",
      "917  0.204082       0.69     0.290216        0.0  0.795775  0.295455\n",
      "\n",
      "[918 rows x 6 columns]\n",
      "Pre-processed class :\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eepy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# drop non-numeric values\n",
    "X = dataset.drop(['HeartDisease', 'Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope'], axis = 1)\n",
    "y = dataset['HeartDisease']\n",
    "\n",
    "# normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_rescaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(data = X_rescaled, columns = X.columns)\n",
    "print(\"Pre-processed data :\")\n",
    "print(X)\n",
    "\n",
    "categories = [['0', '1']]\n",
    "encoder = OneHotEncoder(categories=categories, sparse=False)\n",
    "y = encoder.fit_transform(y.values.reshape(-1,1))\n",
    "print(\"Pre-processed class :\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, batch_size=100,\n",
       "              hidden_layer_sizes=(23, 17, 13), learning_rate_init=0.4,\n",
       "              max_iter=500, random_state=42, solver=&#x27;sgd&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, batch_size=100,\n",
       "              hidden_layer_sizes=(23, 17, 13), learning_rate_init=0.4,\n",
       "              max_iter=500, random_state=42, solver=&#x27;sgd&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='logistic', batch_size=100,\n",
       "              hidden_layer_sizes=(23, 17, 13), learning_rate_init=0.4,\n",
       "              max_iter=500, random_state=42, solver='sgd')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_test, class_train, class_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Number of nodes in each hidden layer should be (10, 2)\n",
    "# Learning rate should be 0.4\n",
    "# Number of epochs should be 600\n",
    "mlp = MLPClassifier(solver = 'sgd', random_state = 42, activation = 'logistic', learning_rate_init = 0.4, batch_size = 100, hidden_layer_sizes = (23,17,13), max_iter = 500)\n",
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(data_train, class_train)\n",
    "\n",
    "pred = mlp.predict(data_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.7608695652173914\n",
      "Mean Square Error :  0.2391304347826087\n",
      "[[0 1]\n",
      " [0 1]]\n",
      "Confusion Matrix for each label : \n",
      "[[[82 20]\n",
      "  [24 58]]\n",
      "\n",
      " [[58 24]\n",
      "  [20 82]]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.72        82\n",
      "           1       0.77      0.80      0.79       102\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       184\n",
      "   macro avg       0.76      0.76      0.76       184\n",
      "weighted avg       0.76      0.76      0.76       184\n",
      " samples avg       0.76      0.76      0.76       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : \", accuracy_score(class_test, pred))\n",
    "print(\"Mean Square Error : \", mean_squared_error(class_test, pred))\n",
    "\n",
    "print(pred[:2])\n",
    "print(\"Confusion Matrix for each label : \")\n",
    "print(multilabel_confusion_matrix(class_test, pred))\n",
    "\n",
    "print(\"Classification Report : \")\n",
    "print(classification_report(class_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each 2x2 confusion matrix class:\n",
    "- true positive: top left value\n",
    "- false positive: top right value\n",
    "- true negative: bottom right value\n",
    "- false negative: bottom left value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "[0.34782609 0.37391304 0.75652174 0.88695652 0.25217391 0.53913043\n",
      " 0.73684211 0.70175439]\n",
      "MSE\n",
      "[0.65217391 0.62608696 0.24347826 0.11304348 0.74782609 0.46086957\n",
      " 0.26315789 0.29824561]\n",
      "Average Accuracy =  0.5743897787948131\n",
      "Average MSE =  0.4256102212051869\n"
     ]
    }
   ],
   "source": [
    "CV = cross_validate(mlp, X, y, cv=8, scoring=['accuracy', 'neg_mean_squared_error'])\n",
    "print('Accuracy')\n",
    "print(CV['test_accuracy'])\n",
    "print('MSE')\n",
    "print(-1*CV['test_neg_mean_squared_error'])\n",
    "\n",
    "print('Average Accuracy = ', sum(CV['test_accuracy']) / len(CV['test_accuracy']))\n",
    "print('Average MSE = ', sum(-1 * CV['test_neg_mean_squared_error']) / len(CV['test_neg_mean_squared_error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for batch  1  :  0.34782608695652173\n",
      "Mean Square Error for batch  1  :  0.6521739130434783\n",
      "\n",
      "Accuracy for batch  2  :  0.7478260869565218\n",
      "Mean Square Error for batch  2  :  0.25217391304347825\n",
      "\n",
      "Accuracy for batch  3  :  0.8434782608695652\n",
      "Mean Square Error for batch  3  :  0.15217391304347827\n",
      "\n",
      "Accuracy for batch  4  :  0.8608695652173913\n",
      "Mean Square Error for batch  4  :  0.1391304347826087\n",
      "\n",
      "Accuracy for batch  5  :  0.7739130434782608\n",
      "Mean Square Error for batch  5  :  0.21739130434782608\n",
      "\n",
      "Accuracy for batch  6  :  0.7391304347826086\n",
      "Mean Square Error for batch  6  :  0.2608695652173913\n",
      "\n",
      "Accuracy for batch  7  :  0.7368421052631579\n",
      "Mean Square Error for batch  7  :  0.2631578947368421\n",
      "\n",
      "Accuracy for batch  8  :  0.7017543859649122\n",
      "Mean Square Error for batch  8  :  0.2982456140350877\n",
      "\n",
      "Average Accuracy =  0.7189549961861175\n",
      "Average MSE =  0.2794145690312738\n"
     ]
    }
   ],
   "source": [
    "# To find list of accuracy and MSE values\n",
    "# Without using the sklearn function cross_validate()\n",
    "\n",
    "n_splits=8\n",
    "# step 1: randomize the dataset and create k equal size partitions\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "acc = 0\n",
    "mse = 0\n",
    "\n",
    "i = 0 #keep track of batch number\n",
    "# step 5: iterate k times with a different testing subset\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "\n",
    "    # step 2-3: use k-1/k^th partition for the training/testing model\n",
    "    start_train, stop_train = train_indices[0], train_indices[-1]+1\n",
    "    start_test, stop_test = test_indices[0], test_indices[-1]+1\n",
    "    \n",
    "    # perform the training similar to Q1\n",
    "    #this was based on the requirements in Q1\n",
    "    mlp = MLPClassifier(solver = 'sgd', random_state = 42, activation = 'logistic', learning_rate_init = 0.4, batch_size = 100, hidden_layer_sizes = (10, 2), max_iter = 600)\n",
    "    mlp.fit(X[start_train:stop_train], y[start_train:stop_train])\n",
    "    pred = mlp.predict(X[start_test:stop_test])\n",
    "    \n",
    "    # step 4: record the evaluating scores\n",
    "    i+=1\n",
    "    acc += accuracy_score(y[start_test:stop_test], pred)\n",
    "    mse += mean_squared_error(y[start_test:stop_test], pred)\n",
    "    \n",
    "    print(\"\\nAccuracy for batch \", i, \" : \", accuracy_score(y[start_test:stop_test], pred))\n",
    "    print(\"Mean Square Error for batch \", i, \" : \", mean_squared_error(y[start_test:stop_test], pred))\n",
    "\n",
    "# step 6: find the average and select the batch with highest evaluation scores\n",
    "print('\\nAverage Accuracy = ', acc / n_splits)\n",
    "print('Average MSE = ', mse / n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['HeartDisease']\n",
    "set_of_classes = y.value_counts().index.tolist()\n",
    "set_of_classes= pd.DataFrame({'Class': set_of_classes})\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Hyper-parameters :  {'max_iter': 1250, 'learning_rate_init': 0.3, 'hidden_layer_sizes': (5, 7)}\n",
      "Optimal Accuracy :  0.7700582086006178\n"
     ]
    }
   ],
   "source": [
    "max_iterations = [500, 750, 1000, 1250, 1500]\n",
    "hidden_layer_siz = [(5, 7), (7, 13), (13, 10)]\n",
    "learning_rates = 0.15 * np.arange(1, 3)\n",
    "\n",
    "param_grid = dict(learning_rate_init = learning_rates, hidden_layer_sizes = hidden_layer_siz, max_iter = max_iterations)\n",
    "# set model\n",
    "# mlp = MLPClassifier(solver = 'sgd', random_state = 42, activation = 'logistic', learning_rate_init = 0.4, batch_size = 100, hidden_layer_sizes = (23,17,13), max_iter = 500)\n",
    "\n",
    "# For Grid Search\n",
    "# grid = GridSearchCV(estimator = mlp, param_grid = param_grid)\n",
    "\n",
    "# For Random Search\n",
    "grid = RandomizedSearchCV(estimator = mlp, param_distributions = param_grid, n_iter = 20)\n",
    "\n",
    "grid.fit(X,y)\n",
    "\n",
    "print(\"Optimal Hyper-parameters : \", grid.best_params_)\n",
    "print(\"Optimal Accuracy : \", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.75\n",
      "Mean Square Error :  0.24456521739130435\n",
      "[[0 1]\n",
      " [0 1]]\n",
      "Confusion Matrix for each label : \n",
      "[[[72 30]\n",
      "  [16 66]]\n",
      "\n",
      " [[66 16]\n",
      "  [28 74]]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.80      0.74        82\n",
      "           1       0.82      0.73      0.77       102\n",
      "\n",
      "   micro avg       0.75      0.76      0.76       184\n",
      "   macro avg       0.75      0.77      0.76       184\n",
      "weighted avg       0.76      0.76      0.76       184\n",
      " samples avg       0.76      0.76      0.76       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try again w/better params\n",
    "mlp = MLPClassifier(solver = 'sgd', random_state = 42, activation = 'logistic', learning_rate_init = 0.3, batch_size = 100, hidden_layer_sizes = (5, 7), max_iter = 1250)\n",
    "mlp.fit(data_train, class_train)\n",
    "\n",
    "pred = mlp.predict(data_test)\n",
    "\n",
    "print(\"Accuracy : \", accuracy_score(class_test, pred))\n",
    "print(\"Mean Square Error : \", mean_squared_error(class_test, pred))\n",
    "\n",
    "print(pred[:2])\n",
    "print(\"Confusion Matrix for each label : \")\n",
    "print(multilabel_confusion_matrix(class_test, pred))\n",
    "\n",
    "print(\"Classification Report : \")\n",
    "print(classification_report(class_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
